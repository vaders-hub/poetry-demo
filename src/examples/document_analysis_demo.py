"""
ì‹¤ë¬´í˜• ë¬¸ì„œ ë¶„ì„ ë°ëª¨

PDF ë¬¸ì„œë¥¼ LlamaIndexë¡œ ì¸ë±ì‹±í•˜ê³  ì‹¤ë¬´ ì§ˆë¬¸ì— ë‹µë³€í•˜ëŠ” ì˜ˆì œ
1. ë¬¸ì„œ ëª©ì  ë° í•µì‹¬ ë‚´ìš© ìš”ì•½ (ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ)
2. ë¬¸ì œë¡œ ì§€ì ëœ ì£¼ìš” ì‚¬ì•ˆ ì¶”ì¶œ
"""

import asyncio

from llama_index.core import Settings, VectorStoreIndex
from llama_index.llms.openai import OpenAI
from llama_index.embeddings.openai import OpenAIEmbedding

from src.utils import load_pdf_from_path, create_hierarchical_index


# LlamaIndex ì „ì—­ ì„¤ì •
Settings.llm = OpenAI(model="gpt-4o-mini", temperature=0.1)
Settings.embed_model = OpenAIEmbedding(model="text-embedding-3-small")
Settings.chunk_size = 512
Settings.chunk_overlap = 50


def print_section(title: str):
    """ì„¹ì…˜ í—¤ë” ì¶œë ¥"""
    print("\n" + "=" * 80)
    print(f"  {title}")
    print("=" * 80 + "\n")


async def load_pdf_document_with_logging(pdf_path: str):
    """PDF ë¬¸ì„œ ë¡œë“œ (ë¡œê¹… í¬í•¨)"""
    print(f"ğŸ“„ PDF ë¡œë“œ ì¤‘: {pdf_path}")
    documents = await load_pdf_from_path(pdf_path)
    print(f"âœ“ {len(documents)} í˜ì´ì§€ ë¡œë“œ ì™„ë£Œ")
    return documents


async def create_hierarchical_index_with_logging(documents):
    """ê³„ì¸µì  ì¸ë±ìŠ¤ ìƒì„± (ë¡œê¹… í¬í•¨)"""
    print("\nğŸ”§ ê³„ì¸µì  ì¸ë±ìŠ¤ ìƒì„± ì¤‘...")
    index, total_nodes, child_nodes_count = await create_hierarchical_index(documents)
    parent_count = (total_nodes - child_nodes_count) // 2  # ì¶”ì •
    print(
        f"âœ“ ì´ {total_nodes}ê°œ ë…¸ë“œ ìƒì„± (Parent: ~{parent_count}, Child: {child_nodes_count})"
    )
    print("âœ“ ì¸ë±ìŠ¤ ìƒì„± ì™„ë£Œ")
    return index


async def streaming_summary(index: VectorStoreIndex) -> None:
    """
    ì§ˆë¬¸ 1: ë¬¸ì„œì˜ ëª©ì ê³¼ í•µì‹¬ ë‚´ìš© ìš”ì•½ (ìŠ¤íŠ¸ë¦¬ë°)

    ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µì„ í†µí•´ ì‹¤ì‹œê°„ìœ¼ë¡œ ìš”ì•½ ë‚´ìš©ì„ ì¶œë ¥
    """
    print_section("ì§ˆë¬¸ 1: ì´ ë¬¸ì„œì˜ ëª©ì ê³¼ í•µì‹¬ ë‚´ìš©ì„ í•œ ë¬¸ë‹¨ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”")

    query_engine = index.as_query_engine(streaming=True, similarity_top_k=5)

    query = """
    ì´ ë¬¸ì„œì˜ ëª©ì ê³¼ í•µì‹¬ ë‚´ìš©ì„ í•œ ë¬¸ë‹¨(200ì ì´ë‚´)ìœ¼ë¡œ ìš”ì•½í•´ ì£¼ì„¸ìš”.
    ì •ë¶€ì˜ ì •ì±… ë°©í–¥, ì£¼ìš” ì§€ì› ë‚´ìš©, ì˜ˆì‚° ê·œëª¨ ë“±ì„ í¬í•¨í•´ì£¼ì„¸ìš”.
    """

    print("ğŸ’¬ ì§ˆì˜ ì¤‘...\n")
    print("ğŸ“ ìŠ¤íŠ¸ë¦¬ë° ì‘ë‹µ:\n")
    print("-" * 80)

    streaming_response = query_engine.query(query)

    # ìŠ¤íŠ¸ë¦¬ë° ì¶œë ¥
    full_response = ""
    for text in streaming_response.response_gen:  # type: ignore[attr-defined]
        print(text, end="", flush=True)
        full_response += text

    print("\n" + "-" * 80)
    print(f"\nâœ“ ìš”ì•½ ì™„ë£Œ ({len(full_response)}ì)")

    # ì°¸ì¡°ëœ ì†ŒìŠ¤ ë…¸ë“œ ì •ë³´
    if hasattr(streaming_response, "source_nodes"):
        print(f"\nğŸ“š ì°¸ì¡°ëœ ë¬¸ì„œ ì²­í¬: {len(streaming_response.source_nodes)}ê°œ")
        for i, node in enumerate(streaming_response.source_nodes[:3], 1):
            text = getattr(node.node, "text", "")[:100]  # type: ignore[attr-defined]
            print(f"  {i}. ìœ ì‚¬ë„: {node.score:.3f} | í…ìŠ¤íŠ¸: {text}...")


async def extract_issues(index: VectorStoreIndex) -> None:
    """
    ì§ˆë¬¸ 2: ë¬¸ì œë¡œ ì§€ì ëœ ì£¼ìš” ì‚¬ì•ˆ ì¶”ì¶œ

    ë¬¸ì„œì—ì„œ ë¬¸ì œì , ê°œì„ ì‚¬í•­, ë³€ê²½ë‚´ìš© ë“±ì„ ì¶”ì¶œ
    """
    print_section("ì§ˆë¬¸ 2: ì´ ë¬¸ì„œì—ì„œ ë¬¸ì œë¡œ ì§€ì ëœ ì£¼ìš” ì‚¬ì•ˆì€ ë¬´ì—‡ì¸ê°€ìš”?")

    query_engine = index.as_query_engine(
        similarity_top_k=8, response_mode="tree_summarize"
    )

    query = """
    ì´ ì •ë¶€ ì •ì±… ë¬¸ì„œì—ì„œ ë‹¤ìŒ ë‚´ìš©ì„ ì¶”ì¶œí•´ì£¼ì„¸ìš”:
    1. ê¸°ì¡´ì— ì¡´ì¬í•˜ë˜ ë¬¸ì œì ì´ë‚˜ ê°œì„ ì´ í•„ìš”í•œ ì‚¬í•­
    2. 2024ë…„ ëŒ€ë¹„ 2025ë…„ì— ë‹¬ë¼ì§€ëŠ” ë‚´ìš© (ë³€ê²½ì‚¬í•­)
    3. ìƒˆë¡­ê²Œ ì‹ ì„¤ë˜ê±°ë‚˜ í™•ëŒ€ë˜ëŠ” ì§€ì› ì‚¬ì—…

    ê° í•­ëª©ì„ ëª…í™•í•˜ê²Œ êµ¬ë¶„í•˜ì—¬ ì •ë¦¬í•´ì£¼ì„¸ìš”.
    """

    print("ğŸ’¬ ì§ˆì˜ ì¤‘...\n")

    response = query_engine.query(query)

    print("ğŸ“‹ í•µì‹¬ ì´ìŠˆ ì¶”ì¶œ ê²°ê³¼:\n")
    print("-" * 80)
    print(str(response))  # type: ignore[attr-defined]
    print("-" * 80)

    # ì°¸ì¡°ëœ ì†ŒìŠ¤ ë…¸ë“œ ì •ë³´
    print(f"\nğŸ“š ì°¸ì¡°ëœ ë¬¸ì„œ ì²­í¬: {len(response.source_nodes)}ê°œ")

    # ìœ ì‚¬ë„ ë†’ì€ ìˆœìœ¼ë¡œ ì •ë ¬
    sorted_nodes = sorted(
        response.source_nodes, key=lambda x: x.score or 0.0, reverse=True
    )

    print("\nğŸ” ê´€ë ¨ë„ê°€ ë†’ì€ ë¬¸ì„œ ì„¹ì…˜:")
    for i, node in enumerate(sorted_nodes[:5], 1):
        print(f"\n  [{i}] ìœ ì‚¬ë„: {node.score:.3f}")
        text = getattr(node.node, "text", "")[:200]  # type: ignore[attr-defined]
        print(f"      ë‚´ìš©: {text}...")


async def additional_analysis(index: VectorStoreIndex) -> None:
    """
    ì¶”ê°€ ë¶„ì„: ì˜ˆì‚° ê·œëª¨, ì§€ì› ëŒ€ìƒ ë“± êµ¬ì²´ì  ì •ë³´ ì¶”ì¶œ
    """
    print_section("ì¶”ê°€ ë¶„ì„: êµ¬ì²´ì  ì •ë³´ ì¶”ì¶œ")

    query_engine = index.as_query_engine(similarity_top_k=5)

    questions = [
        "2025ë…„ ì†Œìƒê³µì¸ ì§€ì› ì˜ˆì‚° ì´ ê·œëª¨ëŠ” ì–¼ë§ˆì¸ê°€ìš”?",
        "ì‹ ê·œë¡œ ë„ì…ë˜ëŠ” ì£¼ìš” ì‚¬ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?",
        "ê°€ì¥ í° ì˜ˆì‚°ì´ ë°°ì •ëœ ì‚¬ì—…ì€ ë¬´ì—‡ì¸ê°€ìš”?",
    ]

    for i, question in enumerate(questions, 1):
        print(f"\nâ“ ì§ˆë¬¸ {i}: {question}")
        print("-" * 80)

        response = query_engine.query(question)
        print(f"âœ… ë‹µë³€: {str(response)}")  # type: ignore[attr-defined]


async def main():
    """ë©”ì¸ ì‹¤í–‰ í•¨ìˆ˜"""
    print("\n" + "â–ˆ" * 80)
    print("  ì‹¤ë¬´í˜• ë¬¸ì„œ ë¶„ì„ ë°ëª¨ - 2025ë…„ ì†Œìƒê³µì¸ ì§€ì›ì‚¬ì—… ê³µê³  ë¶„ì„")
    print("â–ˆ" * 80)

    # PDF íŒŒì¼ ê²½ë¡œ
    pdf_path = "docs/Reprimand-sample-1.pdf"

    try:
        # 1. PDF ë¬¸ì„œ ë¡œë“œ
        documents = await load_pdf_document_with_logging(pdf_path)

        # 2. ê³„ì¸µì  ì¸ë±ìŠ¤ ìƒì„±
        index = await create_hierarchical_index_with_logging(documents)

        # 3. ì§ˆë¬¸ 1: ë¬¸ì„œ ëª©ì  ë° í•µì‹¬ ë‚´ìš© ìš”ì•½ (ìŠ¤íŠ¸ë¦¬ë°)
        await streaming_summary(index)

        # 4. ì§ˆë¬¸ 2: ë¬¸ì œë¡œ ì§€ì ëœ ì£¼ìš” ì‚¬ì•ˆ ì¶”ì¶œ
        await extract_issues(index)

        # 5. ì¶”ê°€ ë¶„ì„
        await additional_analysis(index)

        print("\n" + "â–ˆ" * 80)
        print("  ë¶„ì„ ì™„ë£Œ!")
        print("â–ˆ" * 80 + "\n")

    except FileNotFoundError as e:
        print(f"\nâŒ ì˜¤ë¥˜: {e}")
        print("   docs í´ë”ì— PDF íŒŒì¼ì„ ë°°ì¹˜í–ˆëŠ”ì§€ í™•ì¸í•´ì£¼ì„¸ìš”.")
    except Exception as e:
        print(f"\nâŒ ì˜ˆìƒì¹˜ ëª»í•œ ì˜¤ë¥˜ ë°œìƒ: {e}")
        import traceback

        traceback.print_exc()


if __name__ == "__main__":
    asyncio.run(main())
