# LlamaIndex API Request Samples

LlamaIndex ì—”ë“œí¬ì¸íŠ¸ í…ŒìŠ¤íŠ¸ë¥¼ ìœ„í•œ ìƒ˜í”Œ Request Body ëª¨ìŒì…ë‹ˆë‹¤.
Swagger UI(http://localhost:8001/docs)ì—ì„œ ë°”ë¡œ ë³µì‚¬í•˜ì—¬ ì‚¬ìš©í•  ìˆ˜ ìˆìŠµë‹ˆë‹¤.

---

## ğŸ“‹ ëª©ì°¨

1. [ê¸°ë³¸ ë²¡í„° ì¸ë±ìŠ¤](#1-ê¸°ë³¸-ë²¡í„°-ì¸ë±ìŠ¤)
2. [ë²¡í„° ì¸ë±ìŠ¤ ì¿¼ë¦¬](#2-ë²¡í„°-ì¸ë±ìŠ¤-ì¿¼ë¦¬)
3. [ê³„ì¸µì  ì¸ë±ìŠ¤](#3-ê³„ì¸µì -ì¸ë±ìŠ¤)
4. [JSON ë¬¸ì„œ ì¸ë±ì‹±](#4-json-ë¬¸ì„œ-ì¸ë±ì‹±)
5. [í…Œì´ë¸” ë°ì´í„° ì¸ë±ì‹±](#5-í…Œì´ë¸”-ë°ì´í„°-ì¸ë±ì‹±)
6. [ë‹¤ì¤‘ ì¸ë±ìŠ¤ Router](#6-ë‹¤ì¤‘-ì¸ë±ìŠ¤-router)
7. [Router ì¿¼ë¦¬](#7-router-ì¿¼ë¦¬)
8. [ì¬ê·€ì  ê²€ìƒ‰](#8-ì¬ê·€ì -ê²€ìƒ‰)
9. [ì»¤ìŠ¤í…€ ë…¸ë“œ](#9-ì»¤ìŠ¤í…€-ë…¸ë“œ)
10. [ì¸ë±ìŠ¤ ê´€ë¦¬](#10-ì¸ë±ìŠ¤-ê´€ë¦¬)

---

## 1. ê¸°ë³¸ ë²¡í„° ì¸ë±ìŠ¤

### Endpoint: `POST /llamaindex/basic-vector-index`

#### ìƒ˜í”Œ 1: ì§§ì€ ë¬¸ì„œ

```json
{
  "text": "LlamaIndex is a data framework for LLM applications to ingest, structure, and access private or domain-specific data.",
  "doc_id": "intro_doc"
}
```

#### ìƒ˜í”Œ 2: ê¸°ìˆ  ë¬¸ì„œ

```json
{
  "text": "FastAPI is a modern, fast web framework for building APIs with Python 3.7+. It is based on standard Python type hints and provides automatic API documentation, data validation, and async support.",
  "doc_id": "fastapi_doc"
}
```

#### ìƒ˜í”Œ 3: ê¸´ ë¬¸ì„œ

```json
{
  "text": "Machine learning is a subset of artificial intelligence that focuses on building systems that learn from data. The field encompasses supervised learning (classification, regression), unsupervised learning (clustering, dimensionality reduction), and reinforcement learning. Deep learning, a subset of machine learning, uses neural networks with multiple layers to model complex patterns. Popular frameworks include TensorFlow, PyTorch, and scikit-learn.",
  "doc_id": "ml_overview"
}
```

---

## 2. ë²¡í„° ì¸ë±ìŠ¤ ì¿¼ë¦¬

### Endpoint: `POST /llamaindex/query-vector-index`

#### ìƒ˜í”Œ 1: ê¸°ë³¸ ì§ˆë¬¸

```json
{
  "query": "What is LlamaIndex?",
  "index_id": "vector_intro_doc"
}
```

#### ìƒ˜í”Œ 2: êµ¬ì²´ì  ì§ˆë¬¸

```json
{
  "query": "What are the key features of FastAPI?",
  "index_id": "vector_fastapi_doc"
}
```

#### ìƒ˜í”Œ 3: ë¹„êµ ì§ˆë¬¸

```json
{
  "query": "What is the difference between supervised and unsupervised learning?",
  "index_id": "vector_ml_overview"
}
```

---

## 3. ê³„ì¸µì  ì¸ë±ìŠ¤

### Endpoint: `POST /llamaindex/hierarchical-index`

#### ìƒ˜í”Œ 1: ê¸°ìˆ  ë¬¸ì„œ ì„¹ì…˜

```json
{
  "sections": [
    {
      "title": "Introduction",
      "text": "LlamaIndex is a powerful data framework designed specifically for Large Language Model (LLM) applications. It provides comprehensive tools for data ingestion, indexing, and retrieval. The framework supports various data sources including documents, databases, and APIs. With LlamaIndex, developers can build sophisticated RAG (Retrieval Augmented Generation) systems that combine the power of LLMs with private or domain-specific data.",
      "level": 1
    },
    {
      "title": "Core Features",
      "text": "The core features of LlamaIndex include data connectors for over 100 data sources, flexible indexing strategies including vector stores and hierarchical indices, advanced query engines with support for semantic search, and composable architecture that allows mixing and matching different components. The framework also provides built-in observability, caching mechanisms, and optimization tools for production deployments.",
      "level": 1
    },
    {
      "title": "Use Cases",
      "text": "Common use cases for LlamaIndex include building chatbots over private documents, creating question-answering systems for enterprise knowledge bases, developing semantic search engines, implementing document summarization pipelines, and constructing multi-modal search systems. The framework is particularly useful in domains like legal tech, healthcare, finance, and customer support where access to specialized knowledge is crucial.",
      "level": 1
    }
  ],
  "doc_id": "llamaindex_guide"
}
```

#### ìƒ˜í”Œ 2: ì œí’ˆ ë§¤ë‰´ì–¼

```json
{
  "sections": [
    {
      "title": "Getting Started",
      "text": "To get started with our product, first install the required dependencies using pip install. Then configure your API keys in the environment variables. Create a new project using our CLI tool and initialize the configuration file. The setup process typically takes 5-10 minutes for first-time users.",
      "level": 1
    },
    {
      "title": "Configuration",
      "text": "Configuration options include model selection (choose from GPT-4, GPT-3.5, or custom models), embedding model settings (OpenAI or local models), chunk size and overlap parameters (recommended: 512 with 50 overlap), and retrieval settings such as top-k values and similarity thresholds.",
      "level": 1
    },
    {
      "title": "Advanced Usage",
      "text": "Advanced features include custom node parsers for specialized document structures, hybrid search combining vector and keyword approaches, re-ranking with cross-encoders for improved accuracy, and streaming responses for real-time user feedback. Enterprise users can also leverage distributed indexing and GPU acceleration.",
      "level": 1
    }
  ],
  "doc_id": "product_manual"
}
```

---

## 4. JSON ë¬¸ì„œ ì¸ë±ì‹±

### Endpoint: `POST /llamaindex/json-index`

#### ìƒ˜í”Œ 1: ì œí’ˆ ì •ë³´

```json
{
  "json_data": {
    "product": {
      "id": "PROD-001",
      "name": "Wireless Noise-Cancelling Headphones",
      "category": "Electronics",
      "brand": "TechAudio",
      "specs": {
        "battery_life": "30 hours",
        "connectivity": "Bluetooth 5.0",
        "noise_cancellation": true,
        "weight": "250g",
        "drivers": "40mm"
      },
      "price": {
        "amount": 299.99,
        "currency": "USD"
      },
      "reviews": [
        {
          "rating": 5,
          "comment": "Excellent sound quality and comfort!",
          "date": "2024-01-10"
        },
        {
          "rating": 4,
          "comment": "Great product but a bit pricey",
          "date": "2024-01-12"
        }
      ]
    }
  },
  "doc_id": "product_headphones"
}
```

#### ìƒ˜í”Œ 2: ì‚¬ìš©ì í”„ë¡œí•„

```json
{
  "json_data": {
    "user": {
      "id": "USR-456",
      "name": "Jane Smith",
      "email": "jane.smith@example.com",
      "profile": {
        "age": 28,
        "location": "San Francisco, CA",
        "occupation": "Software Engineer",
        "interests": ["AI", "Machine Learning", "Web Development"]
      },
      "settings": {
        "notifications": true,
        "theme": "dark",
        "language": "en"
      },
      "activity": {
        "last_login": "2024-01-14T10:30:00Z",
        "total_queries": 1523,
        "favorite_topics": ["Python", "FastAPI", "LlamaIndex"]
      }
    }
  },
  "doc_id": "user_jane"
}
```

#### ìƒ˜í”Œ 3: API ì‘ë‹µ ë°ì´í„°

```json
{
  "json_data": {
    "api_response": {
      "status": "success",
      "data": {
        "employees": [
          {
            "id": 1,
            "name": "John Doe",
            "department": "Engineering",
            "position": "Senior Developer",
            "skills": ["Python", "JavaScript", "Docker"]
          },
          {
            "id": 2,
            "name": "Alice Brown",
            "department": "Data Science",
            "position": "ML Engineer",
            "skills": ["Python", "TensorFlow", "SQL"]
          }
        ],
        "metadata": {
          "total_count": 2,
          "page": 1,
          "timestamp": "2024-01-14T15:00:00Z"
        }
      }
    }
  },
  "doc_id": "api_employees"
}
```

---

## 5. í…Œì´ë¸” ë°ì´í„° ì¸ë±ì‹±

### Endpoint: `POST /llamaindex/table-index`

#### ìƒ˜í”Œ 1: ì§ì› ë°ì´í„°

```json
{
  "csv_data": "name,age,city,department,salary\nJohn Smith,35,New York,Engineering,95000\nJane Doe,28,San Francisco,Design,85000\nBob Johnson,42,Seattle,Management,110000\nAlice Williams,31,Boston,Data Science,92000\nCharlie Brown,29,Austin,Marketing,78000",
  "doc_id": "employees_table"
}
```

#### ìƒ˜í”Œ 2: ì œí’ˆ ì¬ê³ 

```json
{
  "csv_data": "product_id,product_name,category,quantity,price,supplier\nP001,Laptop,Electronics,45,1299.99,TechCorp\nP002,Mouse,Accessories,150,29.99,PeriphCo\nP003,Keyboard,Accessories,89,79.99,PeriphCo\nP004,Monitor,Electronics,32,399.99,ScreenPro\nP005,USB Cable,Accessories,200,9.99,CableTech",
  "doc_id": "inventory_table"
}
```

#### ìƒ˜í”Œ 3: íŒë§¤ ë°ì´í„°

```json
{
  "csv_data": "date,product,quantity,revenue,region\n2024-01-01,Widget A,120,12000,North\n2024-01-01,Widget B,85,8500,South\n2024-01-02,Widget A,95,9500,East\n2024-01-02,Widget C,150,22500,West\n2024-01-03,Widget B,110,11000,North",
  "doc_id": "sales_table"
}
```

---

## 6. ë‹¤ì¤‘ ì¸ë±ìŠ¤ Router

### Endpoint: `POST /llamaindex/multi-index`

#### ìƒ˜í”Œ 1: í˜¼í•© ë¬¸ì„œ ì„¸íŠ¸

```json
{
  "documents": [
    {
      "id": "tech_1",
      "text": "LlamaIndex provides powerful data connectors that can ingest data from various sources including APIs, databases, PDFs, and web pages. The framework automatically handles parsing and chunking.",
      "category": "technical"
    },
    {
      "id": "business_1",
      "text": "Our company was founded in 2020 and has grown to 150 employees across 5 offices worldwide. We serve over 1000 enterprise clients in the tech industry.",
      "category": "business"
    },
    {
      "id": "feature_1",
      "text": "Key features include hierarchical indexing, metadata filtering, recursive retrieval, hybrid search, and streaming responses. All features are production-ready and battle-tested.",
      "category": "features"
    }
  ],
  "index_id": "multi_idx_1"
}
```

#### ìƒ˜í”Œ 2: ì œí’ˆ ë¬¸ì„œ

```json
{
  "documents": [
    {
      "id": "overview",
      "text": "Our AI-powered analytics platform helps businesses make data-driven decisions. The platform integrates with all major data sources and provides real-time insights.",
      "category": "overview"
    },
    {
      "id": "pricing",
      "text": "Pricing tiers include Starter ($49/month for up to 10 users), Professional ($199/month for up to 50 users), and Enterprise (custom pricing for unlimited users).",
      "category": "pricing"
    },
    {
      "id": "technical",
      "text": "Built on a microservices architecture using Python, FastAPI, and PostgreSQL. Deployed on AWS with automatic scaling and 99.9% uptime SLA. RESTful APIs with OpenAPI documentation.",
      "category": "technical"
    },
    {
      "id": "support",
      "text": "24/7 customer support via email and chat. Premium customers get dedicated account managers and phone support. Average response time under 2 hours.",
      "category": "support"
    }
  ],
  "index_id": "product_docs"
}
```

---

## 7. Router ì¿¼ë¦¬

### Endpoint: `POST /llamaindex/query-router`

#### ìƒ˜í”Œ 1: ì˜ë¯¸ ê²€ìƒ‰ ì¿¼ë¦¬

```json
{
  "query": "How does the data ingestion process work?",
  "index_id": "multi_idx_1"
}
```

#### ìƒ˜í”Œ 2: ìš”ì•½ ì¿¼ë¦¬

```json
{
  "query": "Give me an overview of the entire product",
  "index_id": "product_docs"
}
```

#### ìƒ˜í”Œ 3: í‚¤ì›Œë“œ ì¿¼ë¦¬

```json
{
  "query": "pricing tiers Enterprise",
  "index_id": "product_docs"
}
```

---

## 8. ì¬ê·€ì  ê²€ìƒ‰

### Endpoint: `POST /llamaindex/recursive-retriever`

#### ìƒ˜í”Œ 1: ê¸°ë³¸ ì§ˆë¬¸

```json
{
  "query": "What are the main features of hierarchical indexing?",
  "index_id": "hierarchical_llamaindex_guide"
}
```

#### ìƒ˜í”Œ 2: ìƒì„¸ ì§ˆë¬¸

```json
{
  "query": "Explain the configuration options in detail",
  "index_id": "hierarchical_product_manual"
}
```

---

## 9. ì»¤ìŠ¤í…€ ë…¸ë“œ

### Endpoint: `POST /llamaindex/custom-nodes`

#### ìƒ˜í”Œ 1: ë¸”ë¡œê·¸ í¬ìŠ¤íŠ¸

```json
{
  "sections": [
    {
      "title": "Introduction to RAG",
      "text": "Retrieval Augmented Generation (RAG) is a technique that enhances Large Language Models by providing them with relevant context from external knowledge sources. Unlike traditional LLMs that rely solely on their training data, RAG systems can access up-to-date information and domain-specific knowledge. This approach significantly improves accuracy and reduces hallucinations. RAG has become essential for enterprise AI applications where accuracy and factual correctness are critical.",
      "level": 1
    },
    {
      "title": "How RAG Works",
      "text": "The RAG process involves three main steps: retrieval, augmentation, and generation. First, when a user asks a question, the system searches a knowledge base (usually a vector database) to find relevant documents or passages. Second, these retrieved documents are combined with the user's question to create an augmented prompt. Finally, the LLM generates a response based on both the question and the retrieved context. This process ensures that responses are grounded in factual information rather than generated from the model's parametric memory alone.",
      "level": 1
    },
    {
      "title": "Benefits and Challenges",
      "text": "RAG offers several key benefits including improved accuracy through grounding in factual sources, ability to cite sources for transparency, easy updates to knowledge without retraining models, and reduced computational costs compared to fine-tuning. However, challenges include ensuring retrieval quality (garbage in, garbage out), managing latency from multiple API calls, handling contradictory information in retrieved documents, and determining optimal chunk sizes for different use cases.",
      "level": 1
    }
  ],
  "doc_id": "rag_blog_post"
}
```

#### ìƒ˜í”Œ 2: íŠœí† ë¦¬ì–¼

```json
{
  "sections": [
    {
      "title": "Step 1: Installation",
      "text": "Begin by installing the required packages using pip. You'll need llama-index, openai, and faiss-cpu. Create a virtual environment first to avoid dependency conflicts. Run 'pip install llama-index llama-index-llms-openai llama-index-embeddings-openai'. This will install the core framework and OpenAI integrations. Installation typically takes 2-3 minutes depending on your internet connection.",
      "level": 1
    },
    {
      "title": "Step 2: Setup",
      "text": "Configure your OpenAI API key by setting the OPENAI_API_KEY environment variable. Import the necessary modules from llama_index.core including Document, VectorStoreIndex, and Settings. Set global configurations such as the LLM model (gpt-4o-mini recommended for cost-effectiveness), embedding model (text-embedding-3-small), chunk size (512 is a good default), and chunk overlap (50 tokens). These settings will apply to all indices you create.",
      "level": 1
    },
    {
      "title": "Step 3: Create Index",
      "text": "Load your documents using Document objects with text and metadata. Create a VectorStoreIndex by calling VectorStoreIndex.from_documents() and passing your document list. The framework will automatically chunk the documents, generate embeddings, and build the vector index. For large document sets, this may take several minutes. Monitor the progress and check for any errors. Once complete, you can persist the index to disk for future use.",
      "level": 1
    },
    {
      "title": "Step 4: Query",
      "text": "Create a query engine from your index using index.as_query_engine(). You can customize the query engine with parameters like similarity_top_k (number of similar chunks to retrieve), response_mode (compact, tree_summarize, etc.), and streaming (enable real-time responses). Execute queries by calling query_engine.query() with your question string. The engine will retrieve relevant chunks, send them to the LLM with your question, and return a comprehensive answer. Examine the source_nodes in the response to see which chunks were used.",
      "level": 1
    }
  ],
  "doc_id": "tutorial_quickstart"
}
```

---

## 10. ì¸ë±ìŠ¤ ê´€ë¦¬

### Endpoint: `GET /llamaindex/list-indices`

No request body needed. Just send a GET request.

### Endpoint: `DELETE /llamaindex/delete-index/{index_id}`

No request body needed. Specify the index_id in the URL path.

**ì˜ˆì‹œ:**
```
DELETE /llamaindex/delete-index/vector_intro_doc
```

---

## ğŸ’¡ ì‚¬ìš© íŒ

### 1. ì¸ë±ìŠ¤ ID íŒ¨í„´

- `vector_{doc_id}`: ê¸°ë³¸ ë²¡í„° ì¸ë±ìŠ¤
- `hierarchical_{doc_id}`: ê³„ì¸µì  ì¸ë±ìŠ¤
- `json_{doc_id}`: JSON ì¸ë±ìŠ¤
- `table_{doc_id}`: í…Œì´ë¸” ì¸ë±ìŠ¤
- `custom_{doc_id}`: ì»¤ìŠ¤í…€ ë…¸ë“œ ì¸ë±ìŠ¤
- ì„ì˜ ID: ë‹¤ì¤‘ ì¸ë±ìŠ¤

### 2. ìµœì ì˜ ì²­í¬ í¬ê¸°

- **ì§§ì€ ë¬¸ì„œ (< 1000ì)**: ì „ì²´ë¥¼ í•˜ë‚˜ì˜ ì¸ë±ìŠ¤ë¡œ
- **ì¤‘ê°„ ë¬¸ì„œ (1000-10000ì)**: chunk_size=512
- **ê¸´ ë¬¸ì„œ (> 10000ì)**: ê³„ì¸µì  ì¸ë±ì‹± ì‚¬ìš©

### 3. ì¿¼ë¦¬ ì „ëµ

- **ê°„ë‹¨í•œ íŒ©íŠ¸ ê²€ìƒ‰**: ë²¡í„° ê²€ìƒ‰
- **ì „ì²´ ìš”ì•½**: Summary Index + Router
- **ì •í™•í•œ í‚¤ì›Œë“œ**: Keyword Index + Router
- **ë³µì¡í•œ ì§ˆë¬¸**: Hierarchical + Recursive Retriever

### 4. í…ŒìŠ¤íŠ¸ ìˆœì„œ

1. `basic-vector-index` â†’ `query-vector-index` (ê¸°ë³¸ íë¦„ ìµíˆê¸°)
2. `hierarchical-index` â†’ `recursive-retriever` (ê³„ì¸µ êµ¬ì¡° ì´í•´)
3. `json-index` / `table-index` (êµ¬ì¡°í™”ëœ ë°ì´í„°)
4. `multi-index` â†’ `query-router` (ìë™ ì„ íƒ)
5. `custom-nodes` (ê³ ê¸‰ ì»¤ìŠ¤í„°ë§ˆì´ì§•)

---

## ğŸ”— ê´€ë ¨ ë¬¸ì„œ

- [LlamaIndex ì™„ë²½ ê°€ì´ë“œ](./LLAMAINDEX_GUIDE.md)
- [ë…ë¦½ ì‹¤í–‰ ì˜ˆì œ](./src/examples/llamaindex_patterns.py)
- [API ë¬¸ì„œ](http://localhost:8001/docs)

---

**ì‘ì„±ì¼**: 2024-01-14
**ë²„ì „**: 1.0
